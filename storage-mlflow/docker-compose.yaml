version: "3.1"

services:
  # Airflow setup
  airflow:
    image: imcp/airflow:2.9.1
    volumes:
      - ./airflow:/opt/airflow
    ports:
      - "8081:8080"
    command: airflow standalone
    networks:
      - data_network

  minio:
    hostname: minio
    image: "minio/minio"
    container_name: minio
    ports:
      - "9001:9001"
      - "9000:9000"
    command: [ "server", "/data", "--console-address", ":9001" ]
    volumes:
      - ./meta/miniodata:/data
    env_file:
      - .env
    networks:
      - data_network
  
  mc:
    image: minio/mc
    container_name: mc
    hostname: mc
    env_file:
      - .env
    volumes:
      - ./meta/mcdata:/data
    entrypoint: >
      /bin/sh -c " until (/usr/bin/mc config host add minio http://minio:9000/ minio minio123) do echo '...waiting...' && sleep 10; done; /usr/bin/mc mb minio/mlflow; tail -f /dev/null;"
    depends_on:     
      - minio
    networks:
      - data_network

  postgres-16:
    image: postgres:16
    container_name: postgres-16
    hostname: postgres-16
    volumes:
      - ./data/postgres_data:/var/lib/postgresql/data
      - ./pg_hba.conf:/tmp/pg_hba.conf
      # - ./load_dataset:/tmp/load_dataset
    command: ["postgres", "-c", "hba_file=/tmp/pg_hba.conf"]
    expose:
      - "5433"
    ports:
      - "5433:5432"
    env_file: .env
    networks:
      - data_network

  mlflow-mysql:
    image: mysql:8.0
    container_name: mysql
    volumes:
      - ./mysql_h:/var/lib/mysql
      - ./dataset:/tmp/dataset
      - ./load_dataset_into_mysql:/tmp/load_dataset
    ports:
      - "3307:3306"
    # env_file: .env
    environment:
      - MYSQL_DATABASE=mlflowdb
      - MYSQL_ROOT_USER=root
      - MYSQL_USER=admin
      - MYSQL_PASSWORD=admin
      - MYSQL_ROOT_PASSWORD=admin
    networks:
      - data_network

  web:
    restart: always
    build: ./docker_image/mlflow
    image: mlflow
    container_name: mlflow_server
    depends_on:
      - mc
      - mlflow-mysql
    ports:
      - "7893:5000"
    networks:
      - data_network
    environment:   
      - MLFLOW_S3_ENDPOINT_URL=http://116.118.50.253:9000
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
    # environment:#   - MLFLOW_S3_ENDPOINT_URL=http://minio:9000/#   - AWS_ACCESS_KEY_ID=minio#   - AWS_SECRET_ACCESS_KEY=minio123
    command: mlflow server --backend-store-uri mysql+pymysql://root:admin@mysql:3306/mlflowdb --default-artifact-root s3://mlflow/ --artifacts-destination s3://mlflow/ --host 0.0.0.0

  redis:
    image: redis:7.4.2
    expose:
      - "6279:6379"
    command: [ "redis-server", "--requirepass", "$$REDIS_PASSWORD", "--maxmemory", "2gb", "--maxmemory-policy", "allkeys-lru", "--set-proc-title", "redis [processed-data]" ]
    environment:
      - REDIS_PASSWORD=redis123
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 30s
      retries: 50
      start_period: 30s
    restart: always  

networks:
  data_network:
    driver: bridge
    name: data_networ
